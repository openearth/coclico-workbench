{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Present and Future Coastal Population\n",
    "\n",
    "Coastal Climate Core Services (CoCliCo) is an European effort to develop an opean web-platform to aid decision making on coastal risk (2021 - 2025). Please have a look at our [website](https://coclicoservices.eu/) to find out more about the project. \n",
    "\n",
    "During this project several datasets will be made available, which can be explored on the platform as well as accessed via cloud-storage buckets. In this notebook, some examples are provided on how to interact with the data using Python, specifically for population projections from [Merkens et al.](https://doi.org/10.1016/j.gloplacha.2016.08.009).\n",
    "\n",
    "- Notebook author: EtiÃ«nne Kras, June 12th 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# import holoviews as hv\n",
    "import cartopy.crs as ccrs\n",
    "# import cartopy.feature as cf\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.ticker as tck\n",
    "import numpy as np\n",
    "# import shapely\n",
    "import pandas as pd\n",
    "import folium\n",
    "import pystac_client\n",
    "# import xarray as xr\n",
    "import rioxarray as rio\n",
    "# import pathlib\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import matplotlib.cm\n",
    "import branca.colormap as cm\n",
    "\n",
    "#import colormaps as cmaps\n",
    "# import pyam # https://pyam-iamc.readthedocs.io/en/latest/index.html\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "from copy import deepcopy\n",
    "from typing import List, Dict\n",
    "from shapely.geometry import shape\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoCliCo STAC catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the CoCliCo STAC catalog\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://storage.googleapis.com/coclico-data-public/coclico/coclico-stac/catalog.json\"\n",
    ")\n",
    "# catalog\n",
    "\n",
    "# list the datasets present in the catalog, we are interested in the slp5 and slp6 sets\n",
    "list(catalog.get_children())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Local Administrative Units (LAU)\n",
    "\n",
    "Note, these are not yet in the STAC so we need to load them from a local source; https://ec.europa.eu/eurostat/web/gisco/geodata/statistical-units/local-administrative-units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to the LAU data\n",
    "LAU_path = r\"p:\\11207608-coclico\\FASTTRACK_DATA\\XX_LAU\"\n",
    "\n",
    "# read the LAU data as geoDataFrame\n",
    "LAU_ds = gpd.read_file(os.path.join(LAU_path, \"LAU_RG_01M_2020_4326.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the LAU dataset on NL\n",
    "LAU_ds_fil = LAU_ds[LAU_ds[\"CNTR_CODE\"].isin([\"NL\"])]\n",
    "#LAU_ds_fil.explore() # plot to see interactive map\n",
    "\n",
    "# sort dataframe on population density\n",
    "LAU_ds_fil = LAU_ds_fil.sort_values(by=\"POP_2020\", ascending=False)\n",
    "\n",
    "# filter the dataset on the most populated municipality\n",
    "LAU_ds_film = LAU_ds_fil.iloc[[0]] # Amsterdam\n",
    "\n",
    "# filter the LAU dataset on the municipalities\n",
    "#LAU_ds_film = LAU_ds_fil[LAU_ds_fil[\"LAU_ID\"] == \"GM0599\"] # Rotterdam\n",
    "\n",
    "# make the plot\n",
    "f = folium.Figure(width=600, height=400)\n",
    "m = LAU_ds_film.explore().add_to(f) # plot to see interactive map\n",
    "folium.TileLayer(\"CartoDB positron\", show=False).add_to(m)  # use folium to add alternative tiles\n",
    "folium.LayerControl().add_to(m)  # use folium to add layer control\n",
    "\n",
    "# show map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Population Projections dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function(s)\n",
    "\n",
    "# function to put items in dataframe\n",
    "def items_to_dataframe(items: List[Dict]) -> pd.DataFrame:\n",
    "    \"\"\"STAC items to Pandas dataframe.\n",
    "\n",
    "    Args:\n",
    "        items (List[Dict]): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: _description_\n",
    "    \"\"\"\n",
    "    _items = []\n",
    "    for i in items:\n",
    "        _i = deepcopy(i)\n",
    "        # _i['geometry'] = shape(_i['geometry'])\n",
    "        # ...  # for example, drop some attributes that you're not interested in\n",
    "        _items.append(_i)\n",
    "    df = pd.DataFrame(pd.json_normalize(_items))\n",
    "    # for field in [\"properties.datetime\"]:\n",
    "    #     if field in df:\n",
    "    #         df[field] = pd.to_datetime(df[field])\n",
    "    # df = df.sort_values(\"properties.datetime\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# read STAC items as Pandas dataframe\n",
    "\n",
    "pop_ds = catalog.get_child(\"pp\")\n",
    "pop_ds_list = list(pop_ds.get_items()) # this is slow as we need to list all items\n",
    "pop_ds_df = items_to_dataframe([i.to_dict() for i in pop_ds_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter items in datasets\n",
    "\n",
    "# define variables\n",
    "area_list = [\"UK\"]  # area list to look into\n",
    "yrs_list = [2010, 2030, 2050, 2100, 2150]  # years to look into \n",
    "key_list = [\"CCS\", \"YRS\", \"AREA\"] # filters, CCS is climate change scenario, YRS is year, AREA is area\n",
    "\n",
    "# index AR5 dataframe on criteria\n",
    "fil_idx  = []\n",
    "pop_dict = {key: [] for key in key_list}\n",
    "for idx, i in enumerate(pop_ds_df.id):\n",
    "    area_s = str(i).split(\".\")[0].split(\"/\")[-1].split(\"_\")[-1]  # ensemble\n",
    "    yrs = int(str(i).split(\"/\")[1][0:4])  # yrs\n",
    "    ccs = str(i).split(\"/\")[0].split(\"SSP\")[-1] # ccs\n",
    "    if area_s in area_list and yrs in yrs_list:  # constraining read ensembles and years\n",
    "        pop_dict[\"CCS\"].append(ccs)\n",
    "        pop_dict[\"YRS\"].append(yrs)\n",
    "        pop_dict[\"AREA\"].append(area_s)\n",
    "        fil_idx.append(idx)\n",
    "\n",
    "# filter pop dataframe and STAC items on index\n",
    "pop_ds_df_fil = pop_ds_df.filter(items = fil_idx, axis=0)\n",
    "pop_ds_fil = [pop_ds_list[i] for i in fil_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine LAU & Population datasets to clip the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all items in the pop collection cropped to the selected LAU\n",
    "ds_clips = []\n",
    "for i in pop_ds_fil:\n",
    "    pop_geom_gdf = gpd.GeoDataFrame(geometry=[shape(i.geometry)]).set_crs(i.properties[\"proj:epsg\"]) # could also do with bbox\n",
    "    if LAU_ds_film.geometry.iloc[0].within(pop_geom_gdf.iloc[0].geometry): # check if geometry within layer\n",
    "        print(i)\n",
    "        ds = rio.open_rasterio(i.assets[\"band_data\"].href, masked=True) # open dataset\n",
    "        ds_clips.append(ds.rio.clip([LAU_ds_film.geometry.iloc[0]])) # clip dataset to LAU and appends to list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameter space (dropdowns in the platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some parameters (SSP and time horizon)\n",
    "ccs = \"1\"  # set climate change scenario for AR5\n",
    "yr = 2010  # set year\n",
    "area = \"EU_UK\"  # set variable (note similar to Europe yet smaller in size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geospatial plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plot\n",
    "\n",
    "# TODO: fix the offset in the lon and lat values compared to the xarray ds_clips[0].plot() (see cell below)\n",
    "for idx, (item, data) in enumerate(zip(pop_ds_fil, ds_clips)):\n",
    "    if item.id == r\"SSP%s/%s/SSP%s_%s_%s.tif\" % (ccs, yr, ccs, yr, area):\n",
    "\n",
    "        pop_data = ds_clips[idx]\n",
    "\n",
    "        lon, lat = np.meshgrid(pop_data.x, pop_data.y)\n",
    "        cmap = matplotlib.cm.get_cmap('viridis')\n",
    "        colormap = cm.linear.viridis.scale(vmin=np.nanmin(np.squeeze(pop_data.values)), vmax=np.nanmax(np.squeeze(pop_data.values)))\n",
    "        colormap.caption = \"A colormap caption\"\n",
    "        normed_data = (np.squeeze(pop_data.values) - np.nanmin(np.squeeze(pop_data.values))) / (np.nanmax(np.squeeze(pop_data.values)) - np.nanmin(np.squeeze(pop_data.values)))\n",
    "        colored_data = cmap(normed_data)\n",
    "\n",
    "\n",
    "        print(item.id)\n",
    "        f = folium.Figure(width=600, height=400)\n",
    "        m = LAU_ds_film.explore(style_kwds=dict(weight=1, opacity=0.4, fillOpacity=.4)).add_to(f) # plot to see interactive map\n",
    "        folium.raster_layers.ImageOverlay(colored_data,\n",
    "                            [[lat.min(), lon.min()], [lat.max(), lon.max()]],\n",
    "                            mercator_project=True, style_kwds=dict(weight=2),\n",
    "                            opacity=0.5).add_to(m)\n",
    "        folium.TileLayer(\"CartoDB positron\", show=True).add_to(m)  # use folium to add alternative tiles\n",
    "        folium.LayerControl().add_to(m)  # use folium to add layer control\n",
    "        m.add_child(colormap)\n",
    "\n",
    "# show map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib ipympl\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots() #figsize=(16, 9)\n",
    "pop_data.plot(ax=ax)\n",
    "LAU_ds_film.plot(ax=ax, alpha=0.5)\n",
    "plt.grid(alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute statistics\n",
    "\n",
    "# people living in the LAU (pop count per cell)\n",
    "for idx, (item, data) in enumerate(zip(pop_ds_fil, ds_clips)):\n",
    "    if item.id == r\"SSP%s/%s/SSP%s_%s_%s.tif\" % (ccs, yr, ccs, yr, area):\n",
    "\n",
    "        print(\"number of people living in %s for SSP%s in %s: %s\"%(LAU_ds_film.LAU_NAME.values[0], ccs, yr, np.int(np.nansum(data.values))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(ax, data, xticks=None, colors=None, total_width=0.8, single_width=1, legend=True):\n",
    "    \"\"\"Draws a bar plot with multiple bars per data point.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax : matplotlib.pyplot.axis\n",
    "        The axis we want to draw our plot on.\n",
    "\n",
    "    data: dictionary\n",
    "        A dictionary containing the data we want to plot. Keys are the names of the\n",
    "        data, the items is a list of the values.\n",
    "\n",
    "        Example:\n",
    "        data = {\n",
    "            \"x\":[1,2,3],\n",
    "            \"y\":[1,2,3],\n",
    "            \"z\":[1,2,3],\n",
    "        }\n",
    "\n",
    "    xticks: array-like, optional\n",
    "        Xticks for the plot\n",
    "\n",
    "    colors : array-like, optional\n",
    "        A list of colors which are used for the bars. If None, the colors\n",
    "        will be the standard matplotlib color cyle. (default: None)\n",
    "\n",
    "    total_width : float, optional, default: 0.8\n",
    "        The width of a bar group. 0.8 means that 80% of the x-axis is covered\n",
    "        by bars and 20% will be spaces between the bars.\n",
    "\n",
    "    single_width: float, optional, default: 1\n",
    "        The relative width of a single bar within a group. 1 means the bars\n",
    "        will touch eachother within a group, values less than 1 will make\n",
    "        these bars thinner.\n",
    "\n",
    "    legend: bool, optional, default: True\n",
    "        If this is set to true, a legend will be added to the axis.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if colors where provided, otherwhise use the default color cycle\n",
    "    if colors is None:\n",
    "        colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "    if xticks is None:\n",
    "        xdata = np.arange(len(data[list(data)[0]]))\n",
    "    else:\n",
    "        xdata = xticks\n",
    "\n",
    "    # Number of bars per group\n",
    "    n_bars = len(data)\n",
    "\n",
    "    # The width of a single bar\n",
    "    bar_width = total_width / n_bars\n",
    "\n",
    "    # List containing handles for the drawn bars, used for the legend\n",
    "    bars = []\n",
    "\n",
    "    # Iterate over all data\n",
    "    for i, (name, values) in enumerate(data.items()):\n",
    "        # The offset in x direction of that bar\n",
    "        x_offset = (i - n_bars / 2) * bar_width + bar_width / 2\n",
    "\n",
    "        # Draw a bar for every value of that type\n",
    "        for x, y in zip(xdata, values):\n",
    "            bar = ax.bar(x + x_offset, y, width=bar_width * single_width, color=colors[i % len(colors)], alpha=0.8)\n",
    "\n",
    "        # Add a handle to the last drawn bar, which we'll need for the legend\n",
    "        bars.append(bar[0])\n",
    "\n",
    "    # Draw legend if we need\n",
    "    if legend:\n",
    "        ax.legend(bars, data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot in time, i.e. retrieve all data\n",
    "\n",
    "# get the data\n",
    "summed_pop = {key: [] for key in [\"SSP1\", \"SSP2\", \"SSP5\"]}\n",
    "summed_pop_yrs = []\n",
    "for idx, (item, data) in enumerate(zip(pop_ds_fil, ds_clips)):\n",
    "    area_s = str(item).split(\".\")[0].split(\"/\")[-1].split(\"_\")[-1]  # ensemble\n",
    "    yrs = int(str(item).split(\"/\")[1][0:4])  # yrs\n",
    "    ccs = str(item).split(\"/\")[0].split(\"SSP\")[-1] # ccs\n",
    "    summed_pop[\"SSP%s\"%ccs].append(np.int(np.nansum(data.values)))\n",
    "    summed_pop_yrs.append(yrs)\n",
    "\n",
    "# make the plot\n",
    "fig, ax = plt.subplots(figsize=(9,5))\n",
    "bar_plot(ax, summed_pop, xticks=summed_pop_yrs, colors=[\"green\", \"blue\", \"red\"], total_width=15, single_width=0.9)\n",
    "#ax.set_xticks(summed_pop_yrs)\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Number of people\")\n",
    "ax.set_title(\"Narratives for population evolution at %s\"%(LAU_ds_film.LAU_NAME.values[0]))\n",
    "ax.set_xticks(summed_pop_yrs)\n",
    "ax.set_xlim(summed_pop_yrs[0]-15/2, summed_pop_yrs[-1]+15/2)\n",
    "ax.grid(alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
