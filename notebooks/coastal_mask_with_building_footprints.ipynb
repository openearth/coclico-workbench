{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fd0662f-d6ca-4fd2-97fe-3806ff4f90e9",
   "metadata": {},
   "source": [
    "# CoCliCo STAC demonstration\n",
    "\n",
    "The purpose of this notebook is to provide an example of how data that is available in the CoCliCo STAC catalog can be combined with other data from other parties using cloud native solutions.  \n",
    "\n",
    "In this dataset we combine the coastal mask (Lincke et al., 2022) with buildings footprints [dataset](https://github.com/microsoft/GlobalMLBuildingFootprints) from Microsoft for The Netherlands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f151b6d8-923d-4849-a76e-cadf45c61fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "# make coclico library importable by appending src from project root to path\n",
    "cwd = pathlib.Path().resolve()\n",
    "PROJ_ROOT = os.path.dirname(cwd)\n",
    "\n",
    "sys.path.append(os.path.join(PROJ_ROOT, \"src\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16290fd5-01e5-4f12-8e3d-2bddf277bc10",
   "metadata": {},
   "source": [
    "## Python tools\n",
    "\n",
    "Below we import some python packages that are often used when working with geospatial data that are hosted in the cloud. \n",
    "\n",
    "These libraries are listed a `environment.yml` file that is available in the root of coclico workbench repository. When the conda package manger is available on the machine, a new environment with these packages can be created by running `conda create -n coclico -f environment.yml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913366f0-8f38-4e10-8958-59d73fb7e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"{PROJ_ROOT}/environment.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e8a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask_geopandas\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pystac_client\n",
    "import rasterio\n",
    "import rioxarray\n",
    "import shapely\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f61582c-546c-4bd0-a1a3-2536eb67accc",
   "metadata": {},
   "source": [
    "### Connect to the coclico-stac catalog\n",
    "\n",
    "The STAC catalog is currenlty hosted in our data bucket at https://storage.googleapis.com/dgds-data-public/coclico/coclico-stac/catalog.json . In future we could (and maybe should) move this to  https://coclicoservices.eu/api/stac/v1\n",
    "\n",
    "With pystac the json files that describe the coclico data can be read into a Python object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c0ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://storage.googleapis.com/dgds-data-public/coclico/coclico-stac/catalog.json\"\n",
    ")\n",
    "catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de018aad-e98d-4c91-ae0f-11f242cf14c8",
   "metadata": {},
   "source": [
    "### Browse the catalog\n",
    "\n",
    "List all dataset collections that are available in the colico catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e873b56-00af-4508-914e-658d1bbb7954",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(catalog.get_children())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78ff005-d533-4fde-a7d0-8b463e8b1289",
   "metadata": {},
   "source": [
    "### Get all items from a certain dataset\n",
    "Make a list of STAC items that are included in the Coastal Mask dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de95ed68-9086-4594-9a58-8f2963f54c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now browse the datasets by interacting with the STAC catalog\n",
    "items = list(catalog.get_child(\"cm\").get_all_items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f884af6b-c385-42fe-8de0-a7f7aa389ecf",
   "metadata": {},
   "source": [
    "### What are STAC items?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956bf122-78da-4d36-96f8-5c7c975a974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(f\"{sys.getsizeof(items[0].to_dict())} bytes\")\n",
    "items[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680de934-89c8-4507-bc96-54ff4753de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "items[0].to_dict()[\"assets\"][\"cm\"][\"href\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b3c7a5-a64e-46dd-81f7-39b9955b8c36",
   "metadata": {},
   "source": [
    "## Index the data without reading the data itself\n",
    "\n",
    "Import a function from the coclico-workbench tools for creating a bounding box geometry, wrapped inside a GeoPandas GeoDataFrame, from a list of bbox coordinates. \n",
    "\n",
    "Working with GeoPandas dataframes is often handy because the library provides spatial indices to the data and has several useful methods such as rtree functionalities.  \n",
    "\n",
    "All the STAC items contain a property that describes the bounding bbox of the data. All these properties are converted to GeoPandas dataframes, which are concatenated into one dataframe.\n",
    "\n",
    "This dataframe describes the spatial extent per bounding box. When the source data (`coastal_mask.tif`) was converted to Cloud Optimized GeoTiff's  we chose a size of 512 x 512 pixels. The coastal mask was derived from the SRTM Dem, so each pixel equivalents approximately 90 meters. Thus, one of these bounding boxes span an area of 45 x 45 km, although the outer boxes may contain less pixels.  \n",
    "\n",
    "Note, here we construct the spatial extent from the STAC items by reading the bbox property in each item. In future, when search functiolaties are implemenented, this will be even easier, as we can use the `pystac_client.Client().search()` method that can handle geometries such as bounding boxes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285dadf8-02cc-4baa-b883-5905da2e9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coclico.utils.geo import geo_bbox\n",
    "\n",
    "bboxes = pd.concat([geo_bbox(i.to_dict()[\"bbox\"]) for i in items])\n",
    "bboxes = bboxes.reset_index(drop=True)\n",
    "bboxes.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaad82fb-b24c-4fbc-84ac-ad6a336b6dfa",
   "metadata": {},
   "source": [
    "### Get items for region of interest\n",
    "\n",
    "Suppose that only that from a certain region is required. In such scenario a bounding box of the region of interest (ROI) can be created using several gis tools, [also online](https://boundingbox.klokantech.com). With GeoPandas it is now easy to get the bboxes that match the ROI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c1d7cc-d08d-44d2-9174-93a043cdf02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = geo_bbox(\n",
    "    [5.2774, 53.0838, 7.1232, 53.5638]\n",
    ")  # rois can be drawn using for example https://boundingbox.klokantech.com/\n",
    "bboxes_roi = gpd.sjoin(bboxes, roi)[bboxes.columns]\n",
    "bboxes_roi.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dd4cb8-53c5-4c77-9dde-ddb5dc60efca",
   "metadata": {},
   "source": [
    "### Filter list of STAC items\n",
    "\n",
    "So now we know the STAC items that describe the ROI without having to download all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4193f876-bb5c-4f75-bb76-a6fbe3faf025",
   "metadata": {},
   "outputs": [],
   "source": [
    "[items[i] for i in bboxes_roi.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7eba7c-e0ac-4449-b229-2a26857bdfc4",
   "metadata": {},
   "source": [
    "## Load data \n",
    "\n",
    "The hrefs point to the blob objects in the data bucket. Many libraries are able to read data directly from these hrefs. Here we create a list of all hrefs in the coastal mask collection. With Dask these are opened using xarray's rasterio engine, as these are raster data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a565b79c-0e28-4b6d-8af0-a56101a4220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_items = list(catalog.get_child(\"cm\").get_all_items())\n",
    "cm_hrefs = [i.assets[\"cm\"].href for i in cm_items]\n",
    "cm_hrefs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ede67fa-b25c-4f27-beeb-2b48bf995dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = dask.distributed.Client(threads_per_worker=1, local_directory=\"/tmp\")\n",
    "print(client)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eda7e2-fe7b-4414-bb6b-2c9d545d54a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "@dask.delayed\n",
    "def lazy_open(href):\n",
    "    chunks = dict(band=1, x=512, y=512)\n",
    "    return xr.open_dataset(href, chunks=chunks, engine=\"rasterio\")\n",
    "\n",
    "\n",
    "das = dask.compute(*[lazy_open(href) for href in cm_hrefs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b7c8b6-017f-4b93-801f-f046ec957d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = xr.combine_by_coords(das).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af5e337-49f1-499f-ba17-13371abea479",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import hvplot.xarray  # qa\n",
    "\n",
    "dataset.squeeze(\"band\").hvplot.image(rasterize=True, x=\"x\", y=\"y\", aspect=\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bfef22-aff6-44e4-b3ce-0c85a32edb52",
   "metadata": {},
   "source": [
    "## Combine coastal mask with building footprints data\n",
    "\n",
    "Microsoft planetary computer hosts a building footprint dataset obtained from very-high resolution satellite imagery using NN's. Here we combine these building footprints with the coastal mask to calculate the building area per flood risk unit. \n",
    "\n",
    "Interacting with Planetary computer is beyond the scope of this tutorial, so a sample of the buildings is stored in the coclico data bucket for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e039f37b-01d7-45cc-84f9-eaab001b312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_geopandas\n",
    "\n",
    "buildings_ddf = dask_geopandas.read_parquet(\n",
    "    \"gs://dgds-data-public/coclico/building_footprints_netherlands/\"\n",
    ")\n",
    "\n",
    "# buildings_fp = pathlib.Path.home().joinpath(\"data\", \"tmp\", \"buildings\")\n",
    "# buildings_ddf = dask_geopandas.read_parquet(buildings_fp)\n",
    "\n",
    "buildings_ddf[\"building_area\"] = buildings_ddf.to_crs(3857).geometry.area / 1e6\n",
    "buildings_ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab9be54-964a-40d0-b932-4335dfd2f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_ddf.partitions[0].compute().iloc[:3000].explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ca25c-af65-4533-845a-1e8f07a9508d",
   "metadata": {},
   "source": [
    "### Vectorize coastal mask data\n",
    "\n",
    "The coastal mask data are rasters, but to overlay this with the building footprints dataset, either the rasters data has to be vectorized or the building data has to be rasterized. Here we will vectorize the coastal mask dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdce51a-34c7-4b2d-a512-1e628185261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from geopandas.array import GeometryDtype\n",
    "\n",
    "\n",
    "@dask.delayed\n",
    "def lazy_vectorize(href):\n",
    "    with rasterio.open(href) as src:\n",
    "        # TODO: change default nodata values in source tif because mask=True does not work now\n",
    "        # currently nodata values are float(\"nan\")\n",
    "        data = src.read(1)  # could be src.read(1, mask=True)\n",
    "\n",
    "        # returns boolean array with true's for nan values\n",
    "        mask = np.isnan(data)\n",
    "\n",
    "        # Create vectors around the raster values that are not float(\"nan\") (masked).\n",
    "        # The rasterio.features.shapes function from rasterio returns dictionaries in geojson\n",
    "        # format of the geometry with the associated value (will always be 1 in this\n",
    "        # dataset. Shapely.geometry.shape can be used to convert the geojson dictionary\n",
    "        # to a geometry. The transform (affine) is used to map the raster values to the\n",
    "        # cartesian coordinates.\n",
    "        shape_generator = [\n",
    "            (shapely.geometry.shape(s), v)\n",
    "            for s, v in rasterio.features.shapes(\n",
    "                data, mask=~mask, transform=src.transform\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # two different methods (doesn't really make a difference):\n",
    "        # 1) generator to dictionary..\n",
    "        # store the geometries and associated values in a dictionary\n",
    "        data = dict(zip([\"geometry\", \"value\"], zip(*shape_generator)))\n",
    "\n",
    "        # cannot construct geodataframe from empty dictionary, so return empty (works with dask)\n",
    "        if not data:\n",
    "            return\n",
    "\n",
    "        gdf = gpd.GeoDataFrame.from_dict(data, crs=src.crs)\n",
    "\n",
    "    #         # 2) or unpack generator in two lists and construct dataframe from that at\n",
    "    #         vectors = list(shape_generator)\n",
    "    #         # Extract the polygon coordinates and values from the list\n",
    "    #         polygons = [polygon for polygon, _ in vectors]\n",
    "    #         values = [value for _, value in vectors]\n",
    "\n",
    "    #         # Create a geopandas dataframe populated with the polygon shapes\n",
    "    #         gdf = gpd.GeoDataFrame(data={\"values\": values}, geometry=polygons, crs=src.crs)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "\n",
    "meta = {\"geometry\": GeometryDtype, \"value\": float}\n",
    "coastal_mask_vec = dask.compute(*[lazy_vectorize(href) for href in cm_hrefs], meta=meta)\n",
    "coastal_mask = pd.concat(coastal_mask_vec)\n",
    "coastal_mask.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e6310e-c5b1-4208-b34c-e5d8475fcc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "coastal_mask = pd.concat(coastal_mask_vec)\n",
    "coastal_mask = coastal_mask.to_crs(3857)  # areas should be computed in p\n",
    "coastal_mask[\"cm_area\"] = coastal_mask.area / 1e6  # compute area in sq km\n",
    "coastal_mask = coastal_mask.loc[\n",
    "    coastal_mask[\"cm_area\"] > 1\n",
    "].copy()  ## only keep flood risk units greater than 1 sq km\n",
    "coastal_mask = coastal_mask.reset_index(drop=True)\n",
    "coastal_mask[\"cm_name\"] = [\n",
    "    \"\".join(str(uuid.uuid4()).split(\"-\")) for i in range(len(coastal_mask.index))\n",
    "]\n",
    "coastal_mask = coastal_mask.to_crs(4326)\n",
    "coastal_mask.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f50c1-a279-401b-b0fd-40fc0ad4ac4b",
   "metadata": {},
   "source": [
    "### Spatial join using Dask Geopandas\n",
    "\n",
    "Load the vectorized coastal maks into Dask GeoPandas so that its spatial join methods can be used.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6a0f2a-14d9-4fdd-b38a-78c7b94fd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coastal_mask_ddf = dask_geopandas.from_geopandas(coastal_mask, npartitions=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b977e5e-810a-4cf6-80be-d6a0c6ffa0ba",
   "metadata": {},
   "source": [
    "### Compute building footprints per coastal mask region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c55994-7729-46c0-ad95-b99e99bf5904",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "joined_ddf = buildings_ddf.sjoin(coastal_mask_ddf)\n",
    "joined = joined_ddf.compute()\n",
    "joined = joined.loc[joined.geometry.is_valid].drop(\"index_right\", axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0874d24-d381-478e-9a0d-5e24cd83b30d",
   "metadata": {},
   "source": [
    "### Visualize results for ROI\n",
    "\n",
    "The data will be plotted using a datashader as the ROI still contains 350K buildings. The geometries have to be converted to a Spatial pandas GeoDataFrame before datashader is able to handle them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a73e3-2b98-4a2b-9102-c5b80bed6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_roi = gpd.sjoin(joined, roi)[joined.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b440ca59-e28d-4c93-8db7-8d14f5cedddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spatialpandas as sp\n",
    "\n",
    "sp_coastal_mask_roi = sp.GeoDataFrame(\n",
    "    gpd.sjoin(coastal_mask, roi)[coastal_mask.columns]\n",
    ")\n",
    "sp_joined_roi = sp.GeoDataFrame(joined_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195851a8-fd1a-40d0-8e4e-c954931a6604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcet as cc\n",
    "import geoviews as gv\n",
    "import holoviews.operation.datashader as hd\n",
    "\n",
    "gv.extension(\"bokeh\")\n",
    "base_layer_hv = gv.tile_sources.EsriTerrain.opts(\n",
    "    width=1200, height=750, bgcolor=\"black\"\n",
    ")\n",
    "coastal_mask_hv = gv.Polygons(sp_coastal_mask_roi.geometry).opts(\n",
    "    fill_color=\"gray\", alpha=0.3, line_color=None\n",
    ")\n",
    "building_footprints_hv = hd.rasterize(gv.Polygons(sp_joined_roi.geometry)).opts(\n",
    "    alpha=1, colorbar=True, clabel=\"Building footprint density\", cmap=cc.fire\n",
    ")\n",
    "base_layer_hv * coastal_mask_hv * building_footprints_hv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c0ebfe0da1198dfcf84fb64f221c7b7e35641f7728e9dc12fbc80e97aca2df12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
