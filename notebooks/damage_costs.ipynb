{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "This notebook allows you to calculate the potential costs of coastal flooding on buildings based on water depth. The calculation uses a vulnerability curve and costs that depend on the country and are refined based on the municipality's GDP. To do this, the user enters the link to their flood map raster as well as the modeling conditions (RP, year, SSP, and defense level)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Activation of the necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio    \n",
    "import sys\n",
    "sys.path.append('/path/to/gdal')  \n",
    "import gc\n",
    "from shapely.geometry import shape\n",
    "gc.collect()\n",
    "from shapely.validation import make_valid\n",
    "import gcsfs\n",
    "from exactextract import exact_extract\n",
    "import warnings\n",
    "import requests\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tempfile\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio import features\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from branca.colormap import LinearColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## request information from the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathflood=# PATH to the coastal flooding raster file, The file must be in .tif format (GeoTIFF).\n",
    "year = \"2010\"# The possible values are 2010 , 2030, 2050, 2100\n",
    "rp=\"100\"# The possible values are static, 1, 100 or 1000\n",
    "defense=\"UNDEFENDED\" # The possible values are HIGH_DEFENDED, LOW_DEFENDED or UNDEFENDED\n",
    "ssp=\"SSP126\" # The possible values are SSP126, SSP245 or SSP585\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_inputs(year, rp, defense, ssp):\n",
    "    valid_years = {\"2010\", \"2030\", \"2050\", \"2100\"}\n",
    "    valid_rps = {\"static\", \"1\", \"100\", \"1000\"}\n",
    "    valid_defenses = {\"HIGH_DEFENDED\", \"LOW_DEFENDED\", \"UNDEFENDED\"}\n",
    "    valid_ssps = {\"SSP126\", \"SSP245\", \"SSP585\"}\n",
    "    errors = []\n",
    "    if year not in valid_years:\n",
    "        errors.append(f\"Invalid year: {year}. Must be one of {sorted(valid_years)}.\")\n",
    "    if rp not in valid_rps:\n",
    "        errors.append(f\"Invalid return period (rp): {rp}. Must be one of {sorted(valid_rps)}.\")\n",
    "    if defense not in valid_defenses:\n",
    "        errors.append(f\"Invalid defense level: {defense}. Must be one of {sorted(valid_defenses)}.\")\n",
    "    if ssp not in valid_ssps:\n",
    "        errors.append(f\"Invalid SSP scenario: {ssp}. Must be one of {sorted(valid_ssps)}.\")\n",
    "    if errors:\n",
    "        raise ValueError(\"\\n\".join(errors))\n",
    "validate_inputs(year, rp, defense, ssp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# CoCliCo connection and data recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"https://storage.googleapis.com/coclico-data-public/coclico/bc_stats/bc_stats.parquet\"\n",
    "local_path = \"CoCliCo_data/cost.parquet\"\n",
    "response = requests.get(path)\n",
    "with open(local_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "path = \"gs://coclico-data-public/coclico/LAU/LAU_2020_NUTS_2021_01M_3035.parquet\"\n",
    "local_path = \"CoCliCo_data/LAU.parquet\"\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "fs.get(path, local_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## list of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_raster(input_raster_path): \n",
    "    with rasterio.open(input_raster_path) as src:\n",
    "        raster_data = src.read(1) \n",
    "        nodata_value = src.nodata\n",
    "        modified_data = np.full(raster_data.shape, np.nan, dtype=rasterio.float32)\n",
    "        if nodata_value is not None:\n",
    "            valid_mask = raster_data != nodata_value\n",
    "            modified_data[valid_mask] = 1\n",
    "        else:\n",
    "            valid_mask = ~np.isnan(raster_data)\n",
    "            modified_data[valid_mask] = 1\n",
    "        return modified_data\n",
    "\n",
    "\n",
    "def raster_value_to_shapefile(raster_path, target_value=1):\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        raster_data = src.read(1)\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "        nodata = src.nodata\n",
    "        shapes_and_values = rasterio.features.shapes(raster_data, transform=transform)\n",
    "        geometries = []\n",
    "        for geom, value in shapes_and_values:\n",
    "            if value == target_value:  \n",
    "                geometries.append({\n",
    "                    'geometry': shape(geom),\n",
    "                    'properties': {'value': value}\n",
    "                })\n",
    "        \n",
    "        gdf = gpd.GeoDataFrame(geometries, crs=crs)\n",
    "        return gdf\n",
    "\n",
    "def reproject_raster(input_raster, target_crs=\"EPSG:3035\"):\n",
    "    with rasterio.open(input_raster) as src:\n",
    "        transform, width, height = calculate_default_transform(\n",
    "            src.crs, target_crs, src.width, src.height, *src.bounds)\n",
    "        kwargs = src.meta.copy()\n",
    "        kwargs.update({\n",
    "            'crs': target_crs,\n",
    "            'transform': transform,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "        output_raster = input_raster.replace(\".tif\", \"_3035.tif\")\n",
    "        with rasterio.open(output_raster, 'w', **kwargs) as dst:\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    source=rasterio.band(src, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=target_crs,\n",
    "                    resampling=Resampling.nearest\n",
    "                )\n",
    "        return output_raster\n",
    "\n",
    "\n",
    "\n",
    "def buildingvulnerabilite(df):\n",
    "    df[\"codevulnerabilite\"]=\"F22\"\n",
    "    return df\n",
    "\n",
    "def _overlay_raster_vector(hazard_raster, features, hazard_crs, nodata=-9999, gridded=False, disable_progress=False):\n",
    "    if hazard_raster.dtypes[0] == 'float64':\n",
    "        hazard_raster = hazard_raster.read(1).astype(np.float32)\n",
    "    area_and_line_objects = features.geom_type.isin([\"Polygon\", \"MultiPolygon\", \"LineString\", \"MultiLineString\"])\n",
    "    point_objects = features.geom_type == \"Point\"\n",
    "    if not gridded:\n",
    "        if area_and_line_objects.sum() > 0:\n",
    "            values_and_coverage_per_area_and_line_object = exact_extract(\n",
    "                hazard_raster, \n",
    "                features[area_and_line_objects],\n",
    "                [\"coverage\", \"values\"],\n",
    "                output=\"pandas\",\n",
    "            )\n",
    "            if not values_and_coverage_per_area_and_line_object.empty:\n",
    "                values_and_coverage_per_area_and_line_object[\"h\"] = values_and_coverage_per_area_and_line_object[\"values\"].apply(np.mean)\n",
    "                values_and_coverage_per_area_and_line_object[\"coverage\"] = values_and_coverage_per_area_and_line_object[\"coverage\"].apply(np.sum)\n",
    "                features.loc[area_and_line_objects, \"coverage\"] = values_and_coverage_per_area_and_line_object[\"coverage\"].values\n",
    "                features.loc[area_and_line_objects, \"h\"] = values_and_coverage_per_area_and_line_object[\"h\"].values\n",
    "            else:\n",
    "                features[\"h\"] = np.nan \n",
    "    if \"h\" in features.columns:\n",
    "        features = features[features[\"h\"].apply(lambda x: not np.isnan(x))]\n",
    "    return features\n",
    "\n",
    "\n",
    "def calculdecout(df,surface,dommage,prix,nom):\n",
    "    df[surface] = pd.to_numeric(df[surface], errors='coerce')\n",
    "    df[prix] = pd.to_numeric(df[prix], errors='coerce')\n",
    "    df[dommage] = pd.to_numeric(df[dommage], errors='coerce')\n",
    "\n",
    "    df[nom]=df[surface]*df[prix]*df[dommage]\n",
    "    return df\n",
    "\n",
    "def save_modified_raster(modified_data, transform, crs, output_path):\n",
    "    with rasterio.open(output_path, 'w', driver='GTiff', \n",
    "                       height=modified_data.shape[0], width=modified_data.shape[1],\n",
    "                       count=1, dtype=modified_data.dtype, crs=crs, transform=transform) as dst:\n",
    "        dst.write(modified_data, 1)\n",
    "\n",
    "def courbedommage(df1,df2):\n",
    "    df1['dommage'] = pd.NA \n",
    "    for index, row in df1.iterrows():\n",
    "        h_value = row['h']\n",
    "        codevulne = row['codevulnerabilite']\n",
    "        if codevulne not in df2.columns:\n",
    "            continue\n",
    "        df2_row = df2[df2['h'] == h_value]\n",
    "        if not df2_row.empty:\n",
    "            dommage_value = df2_row[codevulne].values[0] \n",
    "            df1.at[index, 'dommage'] = dommage_value\n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## link and download of files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### the data is downloaded and stored in the CoCliCo data folder, (infrastructure, vulnerability curve, cost, geographical unit and CoCliCo cost data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unitgeo=\"CoCliCo_data/LAU.parquet\"\n",
    "pathcurve=\"https://github.com/VincentBASCOUL/wb/blob/main/courbevulne.xlsx\"\n",
    "pathprice=\"https://github.com/VincentBASCOUL/wb/blob/main/cout.xlsx\"\n",
    "path_ratio=\"https://drive.google.com/uc?export=download&id=1ajGuXdyaA8sq5VUnJz8gpHmb2wguqSZm\"\n",
    "path_price2=\"https://github.com/VincentBASCOUL/wb/blob/main/coutparpays.xlsx\"\n",
    "response = requests.get(pathcurve)\n",
    "with open(\"CoCliCo_data/vulnerability_curve.xlsx\", \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "response = requests.get(path_ratio)\n",
    "with open(\"CoCliCo_data/gdp_ratio.gpkg\", \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "response = requests.get(path_price2)\n",
    "with open(\"CoCliCo_data/price.xlsx\", \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "opening files, converting flood maps to vector and detecting the region in which it is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "lau=gpd.read_parquet(unitgeo)\n",
    "ratio=gpd.read_file(\"CoCliCo_data/gdp_ratio.gpkg\")          \n",
    "courbe=pd.read_excel(\"CoCliCo_data/courbevulne.xlsx\", sheet_name='Feuil1')\n",
    "pricebuild=pd.read_excel(\"CoCliCo_data/coutparpays.xlsx\", sheet_name='Feuil1')\n",
    "pathflood= reproject_raster(pathflood)\n",
    "flood = modify_raster(pathflood)\n",
    "with tempfile.NamedTemporaryFile(delete=False, suffix=\".tif\") as tmpfile:\n",
    "    temp_raster_path = tmpfile.name\n",
    "    with rasterio.open(pathflood) as src:\n",
    "        save_modified_raster(flood, src.transform, src.crs, temp_raster_path)\n",
    "        pixel_size_x, pixel_size_y = src.res \n",
    "    floodshp = raster_value_to_shapefile(temp_raster_path)\n",
    "intersection= gpd.overlay(lau, floodshp, how=\"intersection\")\n",
    "unique_values = intersection['nuts_2'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## download infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(unique_values)):\n",
    "    path = \"gs://coclico-data-public/coclico/ceed/\"\n",
    "    path=path+unique_values[i]+\"_CEED.parquet\"\n",
    "    local_path = \"CoCliCo_data/CEED/\"+unique_values[i]+\"_CEED.parquet\"\n",
    "    fs = gcsfs.GCSFileSystem()\n",
    "    fs.get(path, local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Calculation of the cost of potential damage based on water height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock2=gpd.GeoDataFrame()\n",
    "for i in range (len(unique_values)):\n",
    "    local_path = \"CoCliCo_data/CEED/\"+unique_values[i]+\"_CEED.parquet\"\n",
    "    exposure=gpd.read_parquet(local_path)\n",
    "    exposure.reset_index(inplace=True)            \n",
    "    exposure=exposure[exposure[\"level_0\"]==\"buildings\"]\n",
    "    exposure = exposure.drop_duplicates(subset=['geometry'])\n",
    "    exposure[\"areacal\"]=exposure.area\n",
    "    if 'level_0' not in exposure.columns:\n",
    "        exposure.reset_index(drop=False, inplace=True)\n",
    "    if 'level_0' in exposure.index.names:\n",
    "        exposure['level_0'] = exposure.index.get_level_values('level_0')\n",
    "        exposure.reset_index(drop=True, inplace=True) \n",
    "    exposure.drop(columns=['level_0'], inplace=True)\n",
    "    exposure=gpd.sjoin(exposure,intersection,how=\"inner\",predicate=\"intersects\")# only building on flood\n",
    "    exposure['geometry'] = exposure['geometry'].apply(lambda geom: make_valid(geom) if not geom.is_valid else geom)\n",
    "    exposure = exposure[exposure['geometry'].is_valid]\n",
    "    exposure = exposure.drop_duplicates(subset=['geometry'])\n",
    "    if 'level_1' in exposure.columns:\n",
    "        exposure.drop(columns=['level_1'], inplace=True)       \n",
    "    if not exposure.empty:  \n",
    "        exposure = buildingvulnerabilite(exposure)       \n",
    "        with rasterio.open(pathflood) as hazard_raster:\n",
    "            exposure = _overlay_raster_vector(hazard_raster=hazard_raster,features=exposure,hazard_crs=3035, nodata=-9999, gridded=False,disable_progress=False) \n",
    "        if 'level_1' in exposure.columns:\n",
    "            exposure.drop(columns=['level_1'], inplace=True)                        \n",
    "        if 'h' in exposure.columns: \n",
    "            exposure['h'] = pd.to_numeric(exposure['h'], errors='coerce')\n",
    "            exposure['h'] = exposure['h'].astype('float64')\n",
    "            exposure[\"h\"]=exposure[\"h\"].round(1)\n",
    "            exposure=courbedommage(exposure, courbe)\n",
    "            exposure[\"price\"]=247.45592\n",
    "            if 'coverage' in exposure.columns:\n",
    "                exposure['coverage'].fillna(0, inplace=True)\n",
    "                try:\n",
    "                    exposure['areacal'] = exposure['coverage'] * abs(pixel_size_x)* abs(pixel_size_y)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(\"Error \")\n",
    "        exposure=calculdecout(exposure, \"areacal\", \"dommage\", \"price\",\"cost\")\n",
    "        stock2=gpd.GeoDataFrame(pd.concat([stock2, exposure], ignore_index=True))\n",
    "pivot_table =stock2.groupby(\"GISCO_ID\", as_index=False).sum(numeric_only=True)\n",
    "pivot_table=pivot_table[[\"GISCO_ID\",\"cost\"]]       \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "compare the results with those of the platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_j = f\"{defense}_MAPS\\\\{rp}\\\\{ssp}\\\\{year}\\\\buildings\"\n",
    "coclico=gpd.read_parquet(\"CoCliCo_data/cost.parquet\")\n",
    "coclico[[\"GISCO_ID\", column_j]]\n",
    "merged = pd.merge(pivot_table, coclico[[\"GISCO_ID\", column_j]], on=\"GISCO_ID\", how='left')\n",
    "merged=merged.rename(columns={column_j: \"coclico\"})\n",
    "print(merged)\n",
    "join_column_gdf = \"GISCO_ID\"\n",
    "join_column_df =\"GISCO_ID\"\n",
    "merged=lau.merge(merged,left_on=join_column_gdf, right_on=join_column_df, how=\"inner\")\n",
    "\n",
    "vmin =merged[\"cost\"].min()\n",
    "vmax = merged[\"cost\"].max()\n",
    "steps = np.linspace(vmin, vmax, 5)\n",
    "colormap = LinearColormap(\n",
    "    colors=[\"white\", \"red\"],\n",
    "    vmin=vmin,\n",
    "    vmax=vmax\n",
    ").to_step(index=steps)\n",
    "merged.explore(column=\"cost\",  # Colorer selon une colonne\n",
    "    cmap=colormap,\n",
    "    legend=True,\n",
    "    legend_kwds={\"position\": \"bottomright\", \"orientation\": \"vertical\"},\n",
    "\n",
    "    tooltip=[\"LAU_NAME\",\"GISCO_ID\", \"cost\", \"coclico\"],  # Infos au survol\n",
    "    style_kwds={\"fillOpacity\": 1.0, \"color\": \"black\", \"weight\": 0.5})\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coclicopost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
